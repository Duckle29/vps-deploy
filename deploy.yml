---
- name: Bootstrap python 3 and such
  hosts: vps
  become: true
  tags:
    - bootstrap
    - python 

  roles:
      - mrlesmithjr.ansible_bootstrap_python

  post_tasks:
    - name: Ensure a locale exists
      locale_gen:
        name: en_US.UTF-8
        state: present

- name: Ensure sudo user mikkel is present
  hosts: vps
  become: true

  vars_files:
    - vars/credentials.yml

  tasks:
    - name: Set become group (Ubuntu)
      set_fact: become_group="sudo"
      when: ansible_os_family | lower == "debian"

    - name: Set become group (Redhat)
      set_fact: become_group="wheel"
      when: ansible_os_family | lower == "redhat"

    - name: Ensure user is present and part of sudoers
      user:
        name: mikkel
        shell: /bin/bash
        groups: '{{ become_group }}'
        append: yes
        password: '{{ system_user_pass }}'
        generate_ssh_key: yes
        ssh_key_bits: 4096

- name: Harden SSH
  hosts: vps
  become: true
  tags:
    - ssh

  vars:
    sshd_log_level: 'INFO'

    
  pre_tasks:
    - name: Set authorized ssh keys
      authorized_key:
        user: mikkel
        state: present
        key: https://github.com/Duckle29.keys

  roles:
    - dev-sec.ssh-hardening

- name: Install acme.sh, aquire certs, and generate dhparams
  hosts: vps
  become: true
  tags:
    - ssl

  vars_files:
    - vars/credentials.yml
    - vars/shared_vars.yml

  vars:
    acme_sh_copy_certs_to_path: '{{ cert_dir }}'
    acme_sh_become_user: "root"

    acme_sh_default_staging: false
    acme_sh_default_force_issue: false
    acme_sh_default_dns_provider: "dns_cf"
    acme_sh_default_dns_sleep: 120
    acme_sh_default_extra_flags_issue: '-k 4096'
    acme_sh_default_install_cert_reloadcmd: "sudo systemctl reload nginx && docker restart {{ mqtt_container_name }}"

    acme_sh_default_extra_flags_install_cert: "--cert-file {{ cert_dir }}/{{ domain }}.cert --ca-file {{ cert_dir }}/{{ domain }}.ca"
    acme_sh_domains:
      - domains: ["{{ domain }}", "*.{{ domain }}", "{{ shlink_domain }}", "*.{{ shlink_domain }}", "snuletek.org", "*.snuletek.org"]
        debug: False 
    
    dhparams_remote_directory: '{{ cert_dir }}'
    dhparams_key_size: 4096

  roles:
    - { role: "nickjj.acme_sh", tags: ["acme_sh"] }
    - duckle29.dhparam

- name: Set hostname of the server
  hosts: vps
  become: true
  tags:
    - hostname
  
  vars_files:
    - vars/shared_vars.yml
  
  tasks:
    - name: Set hostname
      ansible.builtin.hostname:
        name: contabo1.{{ domain }}
    
    - name: Set hostname in /etc/hosts
      ansible.builtin.replace:
        path: /etc/hosts
        regexp: '^((?:[\d|a-fA-F|\.|:])+)(\s+[a-zA-z0-9]+\.contaboserver\.net.*)$'
        replace: \1 contabo1.{{ domain }} contabo1

- name: Ensure the required python-docker bindings are installed
  hosts: vps
  become: true
  tags:
    - docker
    - python
  
  tasks:
    - name: Install docker api and docker-compose api
      pip:
        name:
          - docker
          - docker-compose

- name: Install the latest version of Docker-CE
  hosts: vps
  become: true
  tags:
    - docker
  
  vars:
    docker_edition: 'ce'
    docker_package_state: latest

    docker_service_state: started
    docker_service_enabled: true

    docker_install_compose: true
    
    docker_users:
      - mikkel
  
  roles:
    - geerlingguy.docker

- name: Install nginx
  hosts: vps
  become: true
  tags:
    - nginx

  vars_files:
    - vars/port_usage.yml
    - vars/shared_vars.yml
    - vars/nextcloud/main.yml

  pre_tasks:
    - name: Remove apache
      apt: 
        name: apache2
        state: absent

  roles:
    - nginxinc.nginx

  handlers:
    - name: reload nginx
      service:
        name: nginx
        state: reloaded

  post_tasks:    
    - name: Make snippet directory
      file:
        dest: /etc/nginx/snippets
        state: directory
      notify:
        - reload nginx

    - name: Copy ssl snippet
      template:
        src: templates/nginx/ssl_snippets.j2
        dest: /etc/nginx/snippets/ssl
      notify:
        - reload nginx
    
    - name: Remove default nginx site
      file:
        dest: /etc/nginx/conf.d/default.conf
        state: absent
      notify:
        - reload nginx

- name: Deploy nginx site configs
  hosts: vps
  become: True
  tags:
    - sites
    - nginx

  handlers:
    - name: reload nginx
      service:
        name: nginx
        state: reloaded

  vars_files:
    - vars/port_usage.yml
    - vars/shared_vars.yml
    - vars/nextcloud/main.yml
    - vars/credentials.yml

  tasks:

      # Deploys all .conf.j2 files in templates/nginx/sites
    - name: Deploy site configs
      template:
        src: '{{ item }}'
        dest: '/etc/nginx/conf.d/{{ (item | basename | splitext)[0] }}'
      with_fileglob:
        - templates/nginx/sites/*.conf.j2
      notify:
        - reload nginx

- name: Deploy webhook based websites (resume, blog)
  hosts: vps
  become: true
  tags:
    - webhook
  
  vars_files:
    - vars/shared_vars.yml
    - vars/credentials.yml

  vars:
    wh_server_config: 'templates/webhook_server_config.ini.j2'
    wh_server_file_group: 'nginx'

  pre_tasks:
    - name: Ensure hugo is installed to build the blog
      package:
        name: hugo
        state: present

  
  tasks:

    - name: Ensure webroots are present
      file:
        group: nginx
        owner: gunicorn
        path: '{{ item }}'
        state: directory
      loop:
        - '{{ blog_webroot }}'
        - '{{ mikkelcc_webroot}}'
        - '{{ wifir_webroot }}'

    - name: Install webhook server
      include_role: 
        name: webhook_server

- name: Deploy snuletek.org
  hosts: vps
  become: true
  tags:
    - snuletek
  
  vars_files:
    - vars/shared_vars.yml
    - vars/port_usage.yml

  tasks:    
    - name: Get website
      git:
        repo: https://github.com/Duckle29/snuletek.git
        dest: '{{ snuletekorg_webroot }}'
        update: yes

    - name: Start php-apache container
      community.docker.docker_container:
        name: snuletek-php-apache
        image: php:7.4-apache
        pull: yes
        ports:
          - '{{ portmap.snuletek[0] }}:80'
        networks:
          - name: bridge
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        volumes:
          - '{{ snuletekorg_webroot }}:/var/www/html:ro'
        
        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

- name: Install unifi SDN
  hosts: vps
  become: true
  tags:
    - unifi

  tasks:
    - name: Add an apt key for unifi
      apt_key:
        keyserver: keyserver.ubuntu.com
        id: 06E85760C0A52C50 

    - name: Add unifi repository
      apt_repository:
        repo: deb http://www.ubnt.com/downloads/unifi/debian stable ubiquiti
        state: present
        filename: 100-ubnt-unifi

    - name: Install unifi SDN
      apt:
        name: '{{ item }}'
        state: present
      loop:
        - openjdk-8-jre-headless
        - unifi

- name: Install UNMS
  hosts: vps
  become: true
  tags:
    - unms

  tasks:
    - name: Install dependencies
      apt:
        name: ['curl', 'netcat', 'sudo', 'bash']
        state: present

    - name: Check that UNMS isn't already installed
      stat:
        path: /home/unms/app/unms-cli
      register: unms_stat
  
    - name: Install UNMS
      shell: "curl -fsSL https://unms.com/install > /tmp/unms_inst.sh && sudo bash /tmp/unms_inst.sh --public-https-port 443 --http-port 8081 --https-port 9443 --unattended"
      when: not unms_stat.stat.exists

- name: Install syncplay server
  hosts: vps
  become: true
  tags:
    - syncplay
  
  vars_files:
    - vars/shared_vars.yml
    - vars/port_usage.yml
    - vars/credentials.yml
  
  tasks:
    - name: Make dir for symlinks
      ansible.builtin.file:
        path: '{{ cert_dir }}/{{ domain }}/syncplay'
        state: directory

    - name: Make hardlinks to certs with expected names
      ansible.builtin.file:
        src: '{{ cert_dir }}/{{ item[0] }}'
        dest: '{{ cert_dir }}/{{ domain }}/syncplay/{{ item[1] }}'
        owner: '800'
        group: '800'
        state: hard

      loop:
        - ['{{ domain }}.cert', 'cert.pem']
        - ['{{ domain }}.key', 'privkey.pem']
        - ['{{ domain }}.ca', 'chain.pem']

    - name: Start syncplay-server container
      community.docker.docker_container:
        name: syncplay
        image: ninetaillabs/syncplay-server
        hostname: syncplay.{{ domain }}
        pull: yes
        networks:
          - name: bridge
        ports:
          - '{{ portmap.syncplay[0] }}:{{ portmap.syncplay[0] }}'
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        volumes:
          - '{{ cert_dir }}/{{ domain }}/syncplay:/certs:ro'
        env:
            PASSWORD: '{{ syncplay_pass }}'
            PORT: '{{ portmap.syncplay[0] }}'
            TLS: '/certs'
        
        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

- name: Install sopel (libera)
  hosts: vps
  become: true
  tags:
    - irc
    - sopel
    - libera
  
  vars_files:
    - vars/shared_vars.yml
    - vars/port_usage.yml
    - vars/credentials.yml
  
  tasks:
    - name: Create sopel volume
      community.docker.docker_volume:
        name: sopel_data
    
    - name: Get volume path
      community.docker.docker_volume_info:
        name: sopel_data
      register: sopel_data_volume_info

    - name: Set up folders
      file:
        path: '{{ item }}'
        owner: '100000'
        group: '100000'
        state: directory
      loop:
        - '{{ sopel_data_volume_info.volume.Mountpoint }}'
        - '{{ sopel_data_volume_info.volume.Mountpoint }}/log'


    - name: Copy config to docker volume
      template:
        src: templates/sopel/default.cfg.j2
        dest: '{{ sopel_data_volume_info.volume.Mountpoint }}/default.cfg'
        owner: '100000'
        group: '100000'

    - name: Start sopel container
      community.docker.docker_container:
        name: sopel-libera
        image: sopelirc/sopel:latest
        pull: yes
        networks:
          - name: bridge
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        volumes:
          - 'sopel_data:/home/sopel/.sopel'
        env:
            EXTRA_PYPI_PACKAGES: sopel-modules.wolfram sopel-modules.youtube
        
        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

- name: Set up autotorrent
  hosts: vps
  become: true
  tags:
    - autotorrent
    - deluge

  vars_files:
    - vars/credentials.yml
    - vars/shared_vars.yml

  handlers:
    - name: reload systemd
      systemd:
        daemon_reload: yes

  tasks:
    - name: Add deluge ppa
      apt_repository:
        repo: ppa:deluge-team/stable

    - name: Install deluged
      apt:
        name:
          - deluged
          - deluge-console
        state: present
    
    - name: Add deluge system user
      user:
        name: deluge
        password: '!'
        home: /srv/deluge
        system: yes
        state: present
    
    - name: Add deluged systemd service
      template:
        src: templates/deluge/unitfile.service.j2
        dest: /etc/systemd/system/deluged.service
      when: ansible_service_mgr == 'systemd'
      notify:
        - reload systemd

    - name: Add deluge admin user
      lineinfile:
        line: '{{ deluge_user }}:{{ deluge_pass }}:10'
        path: /srv/deluge/.config/deluge/auth
        create: true

    - name: Ensure file ownership
      file:
        path: /srv/deluge
        recurse: yes
        owner: deluge
        group: deluge

    - name: Start and enable deluged
      service:
        name: deluged
        state: started
        enabled: yes
    
    - name: Allow remote connections
      shell: 'deluge-console "config -s allow_remote True"'

    - pause:
        seconds: 5
        prompt: "Wait for deluged to start"

    - name: Allow remote connections
      shell: deluge-console "config -s allow_remote True"
      become_user: deluge
      register: ret
      failed_when: "'successfully updated' not in ret.stdout"

    - name: Install feedgen
      pip:
        name: feedgen
        executable: pip3
    
    - name: Install pytz
      pip:
        name: pytz
        executable: pip3

    - name: Create web root
      file:
        path: '{{ autotorrent_webroot }}'
        state: directory
        owner: deluge
        group: deluge
    
    - name: Install git
      apt:
        name: git
        state: present

    - name: Get torrentGen
      git:
        repo: https://github.com/Duckle29/torrentGen.git
        dest: /srv/deluge/torrentGen
        update: no
    
    - name: Ensure autoadd folder is present
      file:
        path: '/srv/deluge/torrentGen/autoadd'
        state: directory
        owner: deluge
        group: deluge

    - name: Set correct webroot in torrent gen script
      lineinfile:
        line: "webroot          = '{{ autotorrent_webroot }}/octopi/'"
        regexp: '^webroot +=.+$'
        path: /srv/deluge/torrentGen/octopi/check.py

    - name: Set up cronjob
      cron:
        name: 'autotorrent: Check for new version'
        user: 'deluge'
        minute: '0'
        hour: '*/1'
        job: /usr/bin/python3 /srv/deluge/torrentGen/octopi/check.py

- name: Install VaultWarden
  hosts: vps
  become: true
  tags:
    - bitwarden
    - vaultwarden
  
  vars_files:
    - vars/shared_vars.yml
    - vars/port_usage.yml
    - vars/credentials.yml

  tasks:
    - name: Install passlib
      pip:
        name: passlib

    - name: Generate admin .htpasswd
      community.general.htpasswd:
        path: '{{ bitwarden_htpasswd_path }}'
        name: '{{ bitwarden_admin_user }}'
        password: '{{ bitwarden_admin_pass }}'
        owner: root
        group: www-data
        mode: 0640

    - name: Create VaultWarden network
      community.docker.docker_network:
        name: bitwarden_rs
    
    - name: Create VaultWarden volume
      community.docker.docker_volume:
        name: bitwarden_rs
    
    - name: Set up VaultWarden docker image
      community.docker.docker_container:
        name: bitwarden_rs
        image: vaultwarden/server:latest
        pull: yes
        networks:
          - name: bitwarden_rs
          - name: bridge
        
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        ports:
          - '{{ portmap.bitwarden[0] }}:80'
          - '{{ portmap.bitwarden[1] }}:3012'
        volumes:
          - 'bitwarden_rs:/data/'
        env:
            SIGNUPS_ALLOWED: 'false'
            SHOW_PASSWORD_HINT: 'false'
            INVITATIONS_ALLOWED: 'false'

        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

- name: Set up esp OTA server
  hosts: vps
  become: true
  tags:
    - esp
    - ota
  
  vars_files:
    - vars/shared_vars.yml
    - vars/port_usage.yml
    - vars/credentials.yml

  tasks:
    - name: Create htpasswd directory
      file:
        path: "/srv/esp.{{ domain }}"
        state: directory
        owner: nginx
        group: adm

    - name: Create htpasswd file
      community.general.htpasswd:
        path: "/srv/esp.{{ domain }}/.htpasswd"
        name: "{{ item.username }}"
        password: "{{ item.password }}"
        owner: nginx
        group: adm
        mode: 0640
      loop: '{{ esp_ota_users }}'

    - name: Create ESP OTA server data volume
      community.docker.docker_volume:
        name: esp-ota_data
    
    - name: Create ESP OTA container
      community.docker.docker_container:
        name: esp_update_server
        image: kstobbe/esp-update-server:latest
        networks:
          - name: bridge
        ports:
          - '{{ portmap.esp_ota[0] }}:5000'
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        volumes:
          - 'esp-ota_data:/esp-update-server/bin'
        
        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

- name: Install Nextcloud (docker-apache)
  hosts: vps
  become: True
  tags:
    - nextcloud

  vars_files:
    - vars/shared_vars.yml
    - vars/port_usage.yml
    - vars/credentials.yml

  handlers:
    - name: restart nextcloud
      command: sleep 120 && docker restart nextcloud

  tasks:
    - name: Create nextcloud network
      community.docker.docker_network:
        name: nextcloud

    - name: Create nextcloud mysql volume
      community.docker.docker_volume:
        name: nextcloud_db
    
    - name: Create nextcloud data volume
      community.docker.docker_volume:
        name: nextcloud_data

    - name: Get data volume path
      community.docker.docker_volume_info:
        name: nextcloud_data
      register: nextcloud_data_volume_info

    - name: Set up mysql database for nextcloud
      community.docker.docker_container:
        name: nextcloud-mariadb
        image: mariadb
        command: '--transaction-isolation=READ-COMMITTED --binlog-format=ROW'
        networks:
          - name: nextcloud
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        volumes:
          - 'nextcloud_db:/var/lib/mysql'
        env:
            MYSQL_ROOT_PASSWORD: '{{ mysql_root_pass }}'
            MYSQL_PASSWORD: '{{ nc_database_pass }}'
            MYSQL_DATABASE: 'nextcloud'
            MYSQL_USER: 'nextcloud'

        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

    - name: Set up redis image for nextcloud
      community.docker.docker_container:
        name: nextcloud-redis
        image: redis:alpine
        networks:
          - name: nextcloud
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'

        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

    - name: Set up nextcloud image
      community.docker.docker_container:
        name: nextcloud
        image: nextcloud:27-apache
        pull: yes
        networks:
          - name: nextcloud
          - name: bridge
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        ports:
          - '{{ portmap.nextcloud[0] }}:80'
        volumes:
          - 'nextcloud_data:/var/www/html'
        env:
            NEXTCLOUD_TRUSTED_DOMAINS: 'nextcloud.{{ domain }}'
            REDIS_HOST: nextcloud-redis
            MYSQL_HOST: nextcloud-mariadb
            MYSQL_DATABASE: nextcloud
            MYSQL_USER: nextcloud
            MYSQL_PASSWORD: '{{ nc_database_pass }}'
            NEXTCLOUD_ADMIN_USER: '{{ nc_admin_user }}'
            NEXTCLOUD_ADMIN_PASSWORD: '{{ nc_admin_pass }}'
            OVERWRITEPROTOCOL: 'https'

        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

    - name: Set up cron task for nextcloud
      community.docker.docker_container:
        name: nextcloud-cron
        image: nextcloud:23-apache
        networks:
          - name: nextcloud
        networks_cli_compatible: yes
        restart_policy: 'unless-stopped'
        volumes:
          - 'nextcloud_data:/var/www/html'
        entrypoint: /cron.sh

        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

    # - name: Unset doubled headers
    #   ansible.builtin.lineinfile:
    #     path: '{{ nextcloud_data_volume_info.volume.Mountpoint }}/.htaccess'
    #     regexp: '{{ item }}'
    #     state: 'absent'
    #   loop:
    #     - '^[\t| ]*Header onsuccess unset X-Frame-Options.*$'
    #     - '^[\t| ]*Header always set X-Frame-Options "SAMEORIGIN".*$'
    #     - '^[\t| ]*Header onsuccess unset X-Content-Type-Options.*$'
    #     - '^[\t| ]*Header always set X-Content-Type-Options "nosniff".*$'
    #   notify: restart nextcloud
    
    - name: Set trash retention to max 30 days
      ansible.builtin.lineinfile:
        path: '{{ nextcloud_data_volume_info.volume.Mountpoint }}/config/trash_retention.config.php'
        create: yes
        line: <?php $CONFIG = array ('trashbin_retention_obligation' => 'auto, 30' );
      notify: restart nextcloud

- name: Install Shlink URL shortener
  hosts: vps
  become: True
  tags:
    - shlink
    - urlshort

  vars_files:
    - vars/shared_vars.yml
    - vars/port_usage.yml
    - vars/credentials.yml

  tasks:
    - name: Create shlink network
      community.docker.docker_network:
        name: shlink
      
    - name: Create shlink mysql volume
      community.docker.docker_volume:
        name: shlink_db

    - name: Set up mysql database for shlink
      community.docker.docker_container:
        name: shlink-mariadb
        image: mariadb
        command: '--transaction-isolation=READ-COMMITTED --binlog-format=ROW'
        networks:
          - name: shlink
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        volumes:
          - 'shlink_db:/var/lib/mysql'
        env:
            MYSQL_ROOT_PASSWORD: '{{ mysql_root_pass }}'
            MYSQL_PASSWORD: '{{ shlink_database_pass }}'
            MYSQL_DATABASE: 'shlink'
            MYSQL_USER: 'shlink'
        
        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

    - name: Start Shlink container
      community.docker.docker_container:
        name: shlink
        image: shlinkio/shlink:stable
        networks:
          - name: shlink
          - name: bridge
        ports:
          - '{{ portmap.shlink[0] }}:8080'
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        env:
            SHORT_DOMAIN_HOST: '{{ shlink_domain }}'
            SHORT_DOMAIN_SCHEMA: 'https'
            GEOLITE_LICENSE_KEY: '{{ shlink_geolite_token }}'
            DB_DRIVER: 'maria'
            DB_NAME: shlink
            DB_USER: shlink
            DB_PASSWORD: '{{ shlink_database_pass }}'
            DB_HOST: shlink-mariadb
            DISABLE_TRACK_PARAM: no-track
        
        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

- name: Install Gitea
  hosts: vps
  become: true
  tags:
    - git
    - gittea
  
  vars_files:
    - vars/shared_vars.yml
    - vars/port_usage.yml
    - vars/credentials.yml
  
  handlers:
    - name: restart gitea
      command: docker restart gitea

  tasks:
    - name: Create gitea network
      community.docker.docker_network:
        name: gitea

    - name: Create gitea mysql volume
      community.docker.docker_volume:
        name: gitea_db
    
    - name: Create gitea data volume
      community.docker.docker_volume:
        name: gitea_data
    
    - name: Get data volume path
      community.docker.docker_volume_info:
        name: gitea_data
      register: gitea_data_volume_info

    - name: Set up mysql database for gitea
      community.docker.docker_container:
        name: gitea-mariadb
        image: mariadb
        networks:
          - name: gitea
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        volumes:
          - 'gitea_db:/var/lib/mysql'
        env:
            MYSQL_ROOT_PASSWORD: '{{ mysql_root_pass }}'
            MYSQL_PASSWORD: '{{ gitea_database_pass }}'
            MYSQL_DATABASE: 'gitea'
            MYSQL_USER: 'gitea'

        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

    - name: Set up gitea image
      community.docker.docker_container:
        name: gitea
        image: gitea/gitea:1.14.1
        pull: yes
        networks:
          - name: gitea
          - name: bridge
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        ports:
          - '{{ portmap.gitea[0] }}:3000'
          - '{{ portmap.gitea[1] }}:22'
        volumes:
          - 'gitea_data:/data'
          - '/etc/timezone:/etc/timezone:ro'
          - '/etc/localtime:/etc/localtime:ro'
        env:
            GITEA__database__DB_TYPE: mysql
            GITEA__database__HOST: gitea-mariadb:3306
            GITEA__database__NAME: gitea
            GITEA__database__USER: gitea
            GITEA__database__PASSWD: '{{ gitea_database_pass }}'

        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

    - name: Configure GIT LFS, disabled signing, and SMTP mailer
      community.general.ini_file:
        create: no
        path: '{{ gitea_data_volume_info.volume.Mountpoint }}/gitea/conf/app.ini'
        section: '{{ item[0] }}'
        option: '{{ item[1] }}'
        value: '{{ item[2] }}'
        backup: yes
      loop:
        - ['server', 'LFS_START_SERVER', 'true']
        - ['server', 'ROOT_URL', 'https://git.{{ domain }}/']
        - ['service', 'DISABLE_REGISTRATION', 'true']
        - ['service', 'REQUIRE_SIGNIN_VIEW', 'true']
        - [mailer, 'ENABLED', 'true']
        - [mailer, 'FROM', 'gitea@{{ domain }}']
        - [mailer, 'MAILER_TYPE', 'smtp']
        - [mailer, 'HOST', 'smtp.migadu.com:465']
        - [mailer, 'IS_TLS_ENABLED', 'true']
        - [mailer, 'USER', 'gitea@{{ domain }}']
        - [mailer, 'PASSWD', '{{ gitea_email_pass }}']
      notify:
        - restart gitea

- name: Install bepasty
  hosts: vps
  become: true
  tags:
    - pastebin
    - bepasty
  
  vars_files:
    - vars/shared_vars.yml
    - vars/port_usage.yml
    - vars/credentials.yml
  
  tasks:
    - name: Create bepasty volume
      community.docker.docker_volume:
        name: bepasty_data
    
    - name: Start bepasty container
      community.docker.docker_container:
        name: bepasty
        image: duckle/bepasty:stable
        networks:
          - name: bridge
        ports:
          - '{{ portmap.bepasty[0] }}:5000'
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        volumes:
          - 'bepasty_data:/srv/bepasty'
        env:
            STORAGE_FILESYSTEM_DIRECTORY: "'/srv/bepasty/storage'"
            SITENAME: "'paste.{{ domain }}'"
            UPLOAD_LOCKED: 'False'
            MAX_ALLOWED_FILE_SIZE: '5 * 1000 * 1000 * 1000'
            MAX_BODY_SIZE: '1 * 1024 * 1024'
            STORAGE: "'filesystem'"
            SECRET_KEY: "'{{ bepasty_secret }}'"
            SESSION_COOKIE_SECURE: 'True'
            PERMANENT_SESSION: 'False'
            PERMANENT_SESSION_LIFETIME: '31 * 24 * 3600'
            DEFAULT_PERMISSIONS: "'read'"
            PERMISSIONS: "{{ bepasty_permissions | join(', ') }}"
        
        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

- name: Install and set up CoCalc
  become: True
  hosts: vps
  tags:
    - cocalc

  vars_files:
    - vars/shared_vars.yml
    - vars/port_usage.yml
    - vars/credentials.yml

  tasks:
    - name: Create CoCalc data volume
      community.docker.docker_volume:
        name: cocalc_data

    - name: Start CoCalc container
      community.docker.docker_container:
        name: cocalc
        image: sagemathinc/cocalc
        networks:
          - name: bridge
        ports:
          - '{{ portmap.cocalc[0] }}:443'
        volumes:
          - cocalc_data:/projects
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        
        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

- name: Set up firewall
  hosts: vps
  become: true
  tags:
    - firewall
    - ufw

  vars_files:
    - vars/port_usage.yml
  
  vars:
    ufw_allowed_apps:
      - Deluge
      - Teamspeak 3 - Full
      - UniFi STUN
      - OpenSSH
      - Nginx Full
      - Satisfactory
      - InfluxDB
  
  roles:
    - ufw

- name: Configure unattended upgrades
  hosts: vps
  become: true
  tags:
    - unattended_upgrades
  
  roles:
    - role: jnv.unattended-upgrades
      unattended_mail: 'mikkel@{{ domain }}'

- name: Install thelounge (docker)
  hosts: vps
  become: True
  tags:
    - thelounge
    - irc
    - testlounge

  vars_files:
    - vars/shared_vars.yml
    - vars/port_usage.yml
    - vars/credentials.yml

  tasks:
    # todo: Remember to chmod 'o+x' all the folders leading to the upload dir
    - name: Create thelounge network
      community.docker.docker_network:
        name: thelounge

    - name: Create thelounge data volume
      community.docker.docker_volume:
        name: thelounge_data

    - name: Get data volume path
      community.docker.docker_volume_info:
        name: thelounge_data
      register: thelounge_data_volume_info
    
    - name: Set up config
      template:
        src: templates/thelounge-config.js.j2
        dest: '{{ thelounge_data_volume_info.volume.Mountpoint }}/config.js'

    - name: Start thelounge container
      community.docker.docker_container:
        name: thelounge
        restart: yes
        image: ghcr.io/thelounge/thelounge:latest
        networks:
          - name: thelounge
          - name: bridge
        ports: 
          - '{{ portmap.thelounge[0] }}:9000'
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        volumes:
          - 'thelounge_data:/var/opt/thelounge'
      
        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no

- name: Install mosquitto MQTT broker
  hosts: vps
  become: true
  tags: 
    - mqtt

  vars_files:
    - vars/shared_vars.yml
    - vars/port_usage.yml
    - vars/credentials.yml
  
  tasks:
    - name: Set up Mosquitto volume 
      community.docker.docker_volume:
        name: duQTT_mosquitto
    
    - name: Get volume path
      community.docker.docker_volume_info:
        name: duQTT_mosquitto
      register: mosquitto_volume_info
    
    - name: Make config directory
      file:
        dest: '{{ mosquitto_volume_info.volume.Mountpoint }}/config'
        state: directory

    - name: Make cert directory
      file:
        dest: '{{ mosquitto_volume_info.volume.Mountpoint }}/certs'
        state: directory

    - name: Push custom entrypoint script
      template:
        src: templates/mqtt/custom_entrypoint.sh.j2
        dest: '{{ mosquitto_volume_info.volume.Mountpoint }}/custom_entrypoint.sh'
    
    - name: Make cert directory
      file:
        dest: '{{ mosquitto_volume_info.volume.Mountpoint }}/custom_entrypoint.sh'
        state: file
        mode: u+rwx

    - name: Push config file
      template:
        src: templates/mqtt/mosquitto.conf.j2
        dest: '{{ mosquitto_volume_info.volume.Mountpoint }}/config/mosquitto.conf'
    
    - name: Create password file
      template:
        src: templates/mqtt/passwd.j2
        dest: '{{ mosquitto_volume_info.volume.Mountpoint }}/config/passwd'

    - name: Start Mosquitto container
      community.docker.docker_container:
        name: '{{ mqtt_container_name }}'
        image: eclipse-mosquitto
        networks:
          - name: bridge
        ports:
          - '{{ portmap.mosquitto[0] }}:8083'
          - '{{ portmap.mosquitto[1] }}:8883'
        networks_cli_compatible: yes
        network_mode: default
        restart_policy: 'unless-stopped'
        volumes: 
          - 'duQTT_mosquitto:/mosquitto'
          - '{{ cert_dir }}:/certs:ro'
        entrypoint: '/mosquitto/custom_entrypoint.sh'
        command: '/usr/sbin/mosquitto -c /mosquitto/config/mosquitto.conf'

        container_default_behavior: 'no_defaults'
        tty: no
        read_only: no
        privileged: no
        paused: no
        memory: "0"
        interactive: no
        init: no
        detach: yes
        auto_remove: no


# - name: Install VerneMQ MQTT broker
#   hosts: vps
#   become: true
#   tags:
#     - mqtt
  
#   vars_files:
#     - vars/shared_vars.yml
#     - vars/port_usage.yml
#     - vars/credentials.yml
  
#   tasks:
#     - name: Set up VerneMQ config volume
#       community.docker.docker_volume:
#         name: duQTT-vernemq-cfg

#     - name: Start VerneMQ container
#       community.docker.docker_container:
#         name: duQTT-VerneMQ
#         image: vernemq/vernemq
#         networks:
#           - name: bridge
#         ports:
#           - '{{ portmap.vernemq[0] }}:8883'
#         networks_cli_compatible: yes
#         network_mode: default
#         restart_policy: 'unless-stopped'
#         volumes:
#           - '{{ cert_dir }}:/etc/ssl'
#           - 'duQTT-vernemq-cfg:/etc/vernemq'

#         env:
#           DOCKER_VERNEMQ_ACCEPT_EULA: 'yes'
#           DOCKER_VERNEMQ_LISTENER__SSL__DEFAULT: '0.0.0.0:{{ portmap.vernemq[0] }}'
#           DOCKER_VERNEMQ_LISTENER__SSL__DEFAULT__USE_IDENTITY_AS_USERNAME: 'off'
#           DOCKER_VERNEMQ_LISTENER__SSL__DEFAULT__REQUIRE_CERTIFICATE: 'off'
#           DOCKER_VERNEMQ_LISTENER__SSL__CAFILE: '/etc/ssl/{{ domain }}.pem'
#           DOCKER_VERNEMQ_LISTENER__SSL__KEYFILE: '/etc/ssl/{{ domain }}.key'
#           DOCKER_VERNEMQ_LISTENER__SSL__CERTFILE: '/etc/ssl/{{ domain }}.cert'
#           DOCKER_VERNEMQ_PLUGINS__VMQ_ACL: 'off'

#         container_default_behavior: 'no_defaults'
#         tty: no
#         read_only: no
#         privileged: no
#         paused: no
#         memory: "0"
#         interactive: no
#         init: no
#         detach: yes
#         auto_remove: no

# - name: Install thelounge
#   hosts: vps
#   become: true
#   tags:
#     - thelounge
  
#   tasks:
#     - name: Install nodejs
#       include_role:
#         name: geerlingguy.nodejs
#       vars:
#         nodejs_version: "14.x"
#         nodejs_install_npm_user: root

#     - name: Get the latest release info
#       uri:
#         method: GET
#         url: https://api.github.com/repos/thelounge/thelounge/releases/latest
#         return_content: true
#       register: lounge_json_response
    
#     - name: Latest version is
#       debug:
#         msg: "{{ lounge_json_response.json.assets.0.browser_download_url | regex_replace('^.*thelounge_((\\d\\.*)+)_all\\.deb', '\\1') }}"
#       failed_when: lounge_json_response.json.assets.0.browser_download_url is not regex("thelounge_((\d(?:\.|-)*)+)_all\.deb")

#     - name: Get the latest thelounge .deb
#       get_url: 
#         url: '{{ lounge_json_response.json.assets.0.browser_download_url }}'
#         dest: /root/
#       register: lounge_deb_file
    
#     - name: Install thelounge
#       apt:
#         deb: '{{ lounge_deb_file.dest }}'

#     - name: Remove .deb file
#       file:
#         state: absent
#         path: '{{ lounge_deb_file.dest }}'

#     - name: Stop thelounge before changing config
#       service:
#         name: thelounge
#         state: stopped

#     - name: Set up config
#       template:
#         src: templates/thelounge-config.js.j2
#         dest: /etc/thelounge/config.js

#     - name: Start and enable thelounge
#       service:
#         enabled: yes
#         name: thelounge
#         state: started

# - name: Install pomodoro MC server
#   hosts: vps
#   become: true
#   tags:
#     - minecraft
#     - pomodoro
  
#   vars_files:
#     - vars/shared_vars.yml
#     - vars/port_usage.yml
#     - vars/credentials.yml
  
#   handlers:
#     - name: restart mc pomodoro
#       command: docker restart mc_pomodoro

#   tasks:

#     - name: Create mc pomodoro data volume
#       community.docker.docker_volume:
#         name: mc_pomodoro_data
    
#     - name: Get data volume path
#       community.docker.docker_volume_info:
#         name: mc_pomodoro_data
#       register: mc_pomodoro_data_volume_info

#     - name: Copy server config files
#       ansible.builtin.copy:
#         src: 'templates/minecraft/pomodoro/{{ item }}'
#         dest: '{{ mc_pomodoro_data_volume_info.volume.Mountpoint }}/{{ item }}'
#       loop:
#         - 'eula.txt'
#         - 'ops.json'
#         - 'server.properties'
#         - 'server-icon.png'

#     - name: Ensure the plugin folder is present
#       file:
#         dest: '{{ mc_pomodoro_data_volume_info.volume.Mountpoint }}/plugins/'
#         state: directory

#     - name: Get geyser and floodgate plugins
#       ansible.builtin.get_url:
#         url: '{{ item }}'
#         dest: '{{ mc_pomodoro_data_volume_info.volume.Mountpoint }}/plugins/'
#       loop:
#         - 'https://ci.opencollab.dev/job/GeyserMC/job/Geyser/job/master/967/artifact/bootstrap/spigot/target/Geyser-Spigot.jar'
#         - 'https://ci.opencollab.dev/job/GeyserMC/job/Floodgate/job/master/53/artifact/spigot/target/floodgate-spigot.jar'

#     - name: Set up mcpaper docker image
#       community.docker.docker_container:
#         name: mc_pomodoro
#         image: hchasens/papermc:1.18.1
#         pull: no
#         networks:
#           - name: bridge
#         networks_cli_compatible: yes
#         network_mode: default
#         restart_policy: 'unless-stopped'
#         ports:
#           - '{{ portmap.mc_pomodoro[0] }}:25565'
#           - '{{ portmap.mc_pomodoro[1] }}:25575'
#           - '{{ portmap.mc_pomodoro[2] }}:19132/udp'
#         volumes:
#           - 'mc_pomodoro_data:/papermc'
#         env:
#             MC_VERSION: 1.18.1
#             MC_RAM: 2G

#         container_default_behavior: 'no_defaults'
#         tty: no
#         read_only: no
#         privileged: no
#         paused: no
#         memory: "0"
#         interactive: no
#         init: no
#         detach: yes
#         auto_remove: no

# - name: Install sopel
#   hosts: vps
#   become: true
#   tags:
#     - sopel-freenode

#   vars_files:
#     - vars/credentials.yml

#   vars:
#     sopel_command_prefix: '\$'
    
#     sopel_instance_name: dumDuck
#     sopel_nick: DumDuckBot
#     sopel_auth_user: '{{ sopel_irc_user }}'
#     sopel_auth_pass: '{{ sopel_irc_pass }}'
#     sopel_install_dir: '/srv/sopel'

#     sopel_channels: 
#       - '##botspam'
#       - '#reprap'
#       - '#bigdelta'
#       - '#partkeepr'

#     sopel_bot_owner: 'Duckle'

#     sopel_enabled_plugins:
#       - help
#       - admin
#       - clock
#       - find_updates
#       - reload
#       - currency
#       - remind
#       - search
#       - version
#       - xkcd
#       - wolfram
#       - calc
#       - funreplies
#       - dice
#       - youtube

#     sopel_ignored_nicks:
#       - kthx
#       - mcrib
#       - ghtx
#       - PartKeepr
    
#     sopel_config_extra: |
#       [wolfram]
#       app_id = {{ wolfram_alpha_key }}
#       max_public = 3
#       units = metric

#       [currency]
#       fixer_io_key = {{ fixer_io_key }}
#       auto_convert = true

#       [youtube]
#       api_key = {{ youtube_api_key }}
#       info_items =
#         length
#         date
#         views
#         uploader
#       playlist_watch = true
  
#   handlers:
#     - name: restart sopel
#       become: true
#       service:
#         name: 'sopel-{{ sopel_instance_name }}'
#         state: restarted
  
#   roles:
#     - sopel.sopel
  
#   post_tasks:
#     - name: Install sopel plugins
#       pip:
#         name:
#           - sopel-modules.wolfram
#           - sopel-modules.youtube
#         state: present
#         virtualenv: '{{ sopel_install_dir }}/venv_{{ sopel_instance_name }}'
#         virtualenv_command: '/usr/bin/python3 -m venv'
#       notify: restart sopel